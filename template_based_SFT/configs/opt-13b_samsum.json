{
    "output_dir" : "./checkpoints/opt-13b-lora-samsum",
    "model_name_or_path" : "facebook/opt-13b",
    "run_name" : "opt-13b-samsum",
    "dataset_name" : "samsum",
    "train_in_8bit" : false,
    "num_train_epochs" : 4,
    "max_len" : 512,
    "per_device_train_batch_size" : 8,
    "per_device_eval_batch_size" : 8,
    "fp16" : true,
    "overwrite_output_dir" : true,
    "gradient_accumulation_steps" : 1,
    "learning_rate" : 2e-04,
    "weight_decay" : 0.1,
    "logging_strategy" : "steps",
    "logging_steps" : 50,
    "save_strategy" : "no",
    "do_train" : true,
    "do_eval" : true,
    "report_to" : "wandb",
    "seed" : 42,
    "data_seed" : 42
}