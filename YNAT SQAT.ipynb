{"cells":[{"cell_type":"code","execution_count":57,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11383,"status":"ok","timestamp":1676507572125,"user":{"displayName":"­황태경","userId":"13750175094392078445"},"user_tz":-540},"id":"QKlrOMdMCkCh","outputId":"59e43762-f812-4ba5-de73-5aad2a88aeb7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: transformers in /usr/local/lib/python3.8/dist-packages (4.26.1)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.12.0)\n","Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (0.13.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.21.6)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.26.14)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: datasets in /usr/local/lib/python3.8/dist-packages (2.9.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (23.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.8/dist-packages (from datasets) (0.70.14)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.12.0)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2023.1.0)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.18.0)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.8/dist-packages (from datasets) (3.2.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.9.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n"]}],"source":["!pip install transformers\n","!pip install datasets\n","\n","import os\n","import re\n","import pandas as pd\n","import numpy as np\n","\n","from sklearn import preprocessing\n","\n","from transformers import AutoTokenizer\n","from datasets import Dataset\n","from transformers import DataCollatorWithPadding\n","from transformers import BertForSequenceClassification, TrainingArguments, Trainer\n","from transformers import BertTokenizerFast\n","\n","from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n","\n","import pandas as pd\n","from tqdm import tqdm\n","\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from torch.nn import functional as F\n","\n","import torch\n","from torch.utils.checkpoint import checkpoint\n","import torch.nn as nn\n","\n","# Suppress warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","TRAIN_NOQUANT = True\n","QUANT_TRAIN = True"]},{"cell_type":"code","execution_count":58,"metadata":{"id":"Kg1mEzu8C9-I","executionInfo":{"status":"ok","timestamp":1676507572125,"user_tz":-540,"elapsed":12,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["# You can change the model name here, look up model names from huggingface docs\n","model_name = \"bert-base-multilingual-cased\"\n","batch_size_per_device = 32\n","max_length = 64\n","n_epochs = 3\n","warmup_ratio = .2\n","lr = 5e-5"]},{"cell_type":"code","execution_count":59,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1676507572126,"user":{"displayName":"­황태경","userId":"13750175094392078445"},"user_tz":-540},"id":"U8ZgV_8jF3xG","outputId":"fcc8f16a-06ae-4d78-e5ff-53269fc07aec"},"outputs":[{"output_type":"stream","name":"stdout","text":["There are 1 GPU(s) available.\n","We will use the GPU: Tesla T4\n"]}],"source":["# 디바이스 설정\n","if torch.cuda.is_available():    \n","    device = torch.device(\"cuda\")\n","    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n","    print('We will use the GPU:', torch.cuda.get_device_name(0))\n","else:\n","    device = torch.device(\"cpu\")\n","    print('No GPU available, using the CPU instead.')"]},{"cell_type":"code","execution_count":60,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5955,"status":"ok","timestamp":1676507578073,"user":{"displayName":"­황태경","userId":"13750175094392078445"},"user_tz":-540},"id":"IKbIeqEGEO9k","outputId":"e643a6d1-b50c-4595-ac4f-c61bb13ae97a"},"outputs":[{"output_type":"stream","name":"stderr","text":["loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\",\n","    \"2\": \"LABEL_2\",\n","    \"3\": \"LABEL_3\",\n","    \"4\": \"LABEL_4\",\n","    \"5\": \"LABEL_5\",\n","    \"6\": \"LABEL_6\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1,\n","    \"LABEL_2\": 2,\n","    \"LABEL_3\": 3,\n","    \"LABEL_4\": 4,\n","    \"LABEL_5\": 5,\n","    \"LABEL_6\": 6\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n","loading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/pytorch_model.bin\n","Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n","- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]},{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): Linear(in_features=768, out_features=768, bias=True)\n","              (key): Linear(in_features=768, out_features=768, bias=True)\n","              (value): Linear(in_features=768, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): Linear(in_features=768, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): Linear(in_features=768, out_features=3072, bias=True)\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): Linear(in_features=3072, out_features=768, bias=True)\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): Linear(in_features=768, out_features=768, bias=True)\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",")"]},"metadata":{},"execution_count":60}],"source":["model = BertForSequenceClassification.from_pretrained(model_name, num_labels=7)\n","model.to(device)"]},{"cell_type":"code","execution_count":61,"metadata":{"id":"KhioQnq2Lhlk","executionInfo":{"status":"ok","timestamp":1676507578906,"user_tz":-540,"elapsed":841,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class TorchQuantize(nn.Module):\n","    \"\"\" \n","    Quantize an input tensor to the fixed-point representation. \n","        Args:\n","        input: Input tensor\n","        bits:  Number of bits in the fixed-point\n","    \"\"\"\n","    def __init__(self, bits=0):\n","        super(TorchQuantize, self).__init__()\n","        if bits == 0:\n","            self.quantize = nn.Identity()\n","        elif bits == 1:\n","            self.quantize = TorchBinarize()\n","        else:\n","            self.quantize = TorchRoundToBits(bits)\n","\n","    def forward(self, input):\n","        return self.quantize(input)\n"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"rmGbAxrSLnqc","executionInfo":{"status":"ok","timestamp":1676507578906,"user_tz":-540,"elapsed":5,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class TorchBinarize(nn.Module):\n","    \"\"\" Binarizes a value in the range [-1,+1] to {-1,+1} \"\"\"\n","    def __init__(self):\n","        super(TorchBinarize, self).__init__()\n","\n","    def forward(self, input):\n","        \"\"\"  clip to [-1,1] \"\"\"\n","        input = Clamp.apply(input, -1.0, 1.0)\n","        \"\"\" rescale to [0,1] \"\"\"\n","        input = (input+1.0) / 2.0\n","        \"\"\" round to {0,1} \"\"\"\n","        input = Round.apply(input)\n","        \"\"\" rescale back to {-1,1} \"\"\"\n","        input = input*2.0 - 1.0\n","        return input"]},{"cell_type":"code","execution_count":63,"metadata":{"id":"fuNGdZ79Ln_1","executionInfo":{"status":"ok","timestamp":1676507578907,"user_tz":-540,"elapsed":6,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class TorchRoundToBits(nn.Module):\n","    \"\"\" Quantize a tensor to a bitwidth larger than 1 \"\"\"\n","    def __init__(self, bits=2):\n","        super(TorchRoundToBits, self).__init__()\n","        assert bits > 1, \"RoundToBits is only used with bitwidth larger than 1.\"\n","        self.bits = bits\n","        self.epsilon = 1e-7\n","\n","    def forward(self, input):\n","        \"\"\" extract the sign of each element \"\"\"\n","        sign = torch.sign(input).detach()\n","        \"\"\" get the mantessa bits \"\"\"\n","        input = torch.abs(input)\n","        scaling = torch.max(input).detach() + self.epsilon\n","        input = Clamp.apply( input/scaling ,0.0, 1.0 )\n","        \"\"\" round the mantessa bits to the required precision \"\"\"\n","        input = Round.apply(input * (2.0**self.bits-1.0)) / (2.0**self.bits-1.0)\n","        return input * scaling * sign"]},{"cell_type":"code","execution_count":64,"metadata":{"id":"Ic70CVObLzLZ","executionInfo":{"status":"ok","timestamp":1676507578907,"user_tz":-540,"elapsed":5,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class Round(torch.autograd.Function):\n","    \"\"\"\n","    We can implement our own custom autograd Functions by subclassing\n","    torch.autograd.Function and implementing the forward and backward passes\n","    which operate on Tensors.\n","    \"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, input):\n","        \"\"\"\n","        In the forward pass we receive a Tensor containing the input and return\n","        a Tensor containing the output. ctx is a context object that can be used\n","        to stash information for backward computation. You can cache arbitrary\n","        objects for use in the backward pass using the ctx.save_for_backward method.\n","        \"\"\"\n","        # ctx.save_for_backward(input)\n","        return torch.round(input)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        \"\"\"\n","        In the backward pass we receive a Tensor containing the gradient of the loss\n","        with respect to the output, and we need to compute the gradient of the loss\n","        with respect to the input.\n","        The backward behavior of the round function is defined as the identity function.\n","        \"\"\"\n","        # input, = ctx.saved_tensors\n","        grad_input = grad_output.clone()\n","        return grad_input\n","\n","class Clamp(torch.autograd.Function):\n","    \"\"\"\n","    We can implement our own custom autograd Functions by subclassing\n","    torch.autograd.Function and implementing the forward and backward passes\n","    which operate on Tensors.\n","    \"\"\"\n","\n","    @staticmethod\n","    def forward(ctx, input, min, max):\n","        \"\"\"\n","        In the forward pass we receive a Tensor containing the input and return\n","        a Tensor containing the output. ctx is a context object that can be used\n","        to stash information for backward computation. You can cache arbitrary\n","        objects for use in the backward pass using the ctx.save_for_backward method.\n","        \"\"\"\n","        # ctx.save_for_backward(input)\n","        return torch.clamp(input, min, max)\n","\n","    @staticmethod\n","    def backward(ctx, grad_output):\n","        \"\"\"\n","        In the backward pass we receive a Tensor containing the gradient of the loss\n","        with respect to the output, and we need to compute the gradient of the loss\n","        with respect to the input.\n","        The backward behavior of the clamp function is defined as the identity function.\n","        \"\"\"\n","        # input, = ctx.saved_tensors\n","        grad_input = grad_output.clone()\n","        return grad_input, None, None"]},{"cell_type":"code","execution_count":65,"metadata":{"id":"GczHn62VMgjW","executionInfo":{"status":"ok","timestamp":1676507578907,"user_tz":-540,"elapsed":5,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class GaussianNoise(nn.Module):\n","    \"\"\"Gaussian noise regularizer.\n","    Args:\n","        sigma (float, optional): relative standard deviation used to generate the\n","            noise. Relative means that it will be multiplied by the magnitude of\n","            the value your are adding the noise to. This means that sigma can be\n","            the same regardless of the scale of the vector.\n","        is_relative_detach (bool, optional): whether to detach the variable before\n","            computing the scale of the noise. If `False` then the scale of the noise\n","            won't be seen as a constant but something to optimize: this will bias the\n","            network to generate vectors with smaller values.\n","    \"\"\"\n","\n","    def __init__(self, sigma=0.1, is_relative_detach=False, inference=False, white=False):\n","        super().__init__()\n","        self.sigma = sigma\n","        self.is_relative_detach = is_relative_detach\n","        self.noise = torch.tensor(0).to(\"cuda\")\n","        self.inference = inference\n","        self.white = white\n","\n","    def forward(self, x):\n","        if (self.training and self.sigma > 0) or self.inference:\n","            scale = self.sigma * x.detach() if self.is_relative_detach else self.sigma * x\n","            if not self.white:\n","                sampled_noise = self.noise.repeat(*x.size()).float().normal_() * self.sigma\n","            else:\n","                sampled_noise = self.noise.repeat(*x.size()).float().random_(-1000000,1000000) * self.sigma / 1000000\n","            x = x + sampled_noise\n","        return x "]},{"cell_type":"code","execution_count":66,"metadata":{"id":"X04sjlcSMz-v","executionInfo":{"status":"ok","timestamp":1676507578907,"user_tz":-540,"elapsed":4,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["from torch.autograd import Function\n","\n","class ActFn(Function):\n","\t@staticmethod\n","\tdef forward(ctx, x, alpha, k):\n","\t\tctx.save_for_backward(x, alpha)\n","\t\t# y_1 = 0.5 * ( torch.abs(x).detach() - torch.abs(x - alpha).detach() + alpha.item() )\n","\t\ty = torch.clamp(x, min = 0, max = alpha.item())\n","\t\tscale = (2**k - 1) / alpha\n","\t\ty_q = torch.round( y * scale) / scale\n","\t\treturn y_q\n","\n","\t@staticmethod\n","\tdef backward(ctx, dLdy_q):\n","\t\t# Backward function, I borrowed code from\n","\t\t# https://github.com/obilaniu/GradOverride/blob/master/functional.py\n","\t\t# We get dL / dy_q as a gradient\n","\t\tx, alpha, = ctx.saved_tensors\n","\t\t# Weight gradient is only valid when [0, alpha]\n","\t\t# Actual gradient for alpha,\n","\t\t# By applying Chain Rule, we get dL / dy_q * dy_q / dy * dy / dalpha\n","\t\t# dL / dy_q = argument,  dy_q / dy * dy / dalpha = 0, 1 with x value range \n","\t\tlower_bound      = x < 0\n","\t\tupper_bound      = x > alpha\n","\t\t# x_range       = 1.0-lower_bound-upper_bound\n","\t\tx_range = ~(lower_bound|upper_bound)\n","\t\tgrad_alpha = torch.sum(dLdy_q * torch.ge(x, alpha).float()).view(-1)\n","\t\treturn dLdy_q * x_range.float(), grad_alpha, None"]},{"cell_type":"code","execution_count":67,"metadata":{"id":"kc3gEa5KK-5t","executionInfo":{"status":"ok","timestamp":1676507584397,"user_tz":-540,"elapsed":2,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["class QuantizedLinear(nn.Linear):\n","    \"\"\" \n","    A fully connected layer with its weight tensor and input tensor quantized. \n","    \"\"\"\n","    def __init__(self, in_features, out_features, bias=True, wbits=0, abits=0, pact=False, noise=0, half=False, white=False):\n","        super(QuantizedLinear, self).__init__(in_features, out_features, bias)\n","        self.quantize_w = TorchQuantize(wbits)\n","        self.quantize_a = TorchQuantize(abits)\n","        self.weight_rescale = np.sqrt(1.0/in_features) if (wbits == 1) else 1.0\n","        self.quantize_o = TorchQuantize(abits)\n","        # PACT\n","        self.quant = ActFn.apply\n","        self.k = abits\n","        if pact:\n","            self.alpha = nn.Parameter(torch.tensor(1.)) # trainable clipping factor for PACT\n","        self.pact = pact\n","        if half:\n","            self.noise = GaussianNoise(sigma=noise/2, inference=True, white=white)\n","        else:\n","            self.noise = GaussianNoise(sigma=noise, inference=True, white=white)\n","\n","    def forward(self, input):\n","        \"\"\" \n","        1. Quantize the input tensor\n","        2. Quantize the weight tensor\n","        3. Rescale via McDonnell 2018 (https://arxiv.org/abs/1802.08530)\n","        4. perform matrix multiplication \n","        \"\"\"\n","        if not self.pact:\n","              return F.linear(self.noise(self.quantize_a(input)), \n","                        self.quantize_w(self.weight) * self.weight_rescale, \n","                        self.bias)\n","        else:\n","            return F.linear(self.noise(self.quant(input, self.alpha, self.k)), \n","                        self.quantize_w(self.weight) * self.weight_rescale, \n","                        self.bias)"]},{"cell_type":"code","execution_count":68,"metadata":{"id":"9qPNXR7eISW5","executionInfo":{"status":"ok","timestamp":1676507587377,"user_tz":-540,"elapsed":3,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["def replace_layer(module, name, noise=0.01, k=8):\n","    '''\n","    Replace linear layer to quantized layer\n","    '''\n","    # go through all attributes of module nn.module (e.g. network or layer) and put batch norms if present\n","    for attr_str in dir(module):\n","        target_attr = getattr(module, attr_str)\n","        if type(target_attr) == torch.nn.Linear:\n","            new = QuantizedLinear(target_attr.in_features, target_attr.out_features, True, \n","                                     wbits=k, abits=k, noise=noise)\n","            setattr(module, attr_str, new)\n","\n","    # iterate through immediate child modules. Note, the recursion is done by our code no need to use named_modules()\n","    for name, immediate_child_module in module.named_children():\n","        replace_layer(immediate_child_module, name, noise, k)"]},{"cell_type":"code","execution_count":69,"metadata":{"id":"ODdl7YLoLCBD","executionInfo":{"status":"ok","timestamp":1676507590492,"user_tz":-540,"elapsed":557,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[],"source":["replace_layer(model, 'model', noise=0.01, k=1)"]},{"cell_type":"code","execution_count":70,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1676507590492,"user":{"displayName":"­황태경","userId":"13750175094392078445"},"user_tz":-540},"id":"ZchG6RVQM84W","outputId":"63fe680b-cc1c-49a8-eabc-10cd6f5b86bc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["BertForSequenceClassification(\n","  (bert): BertModel(\n","    (embeddings): BertEmbeddings(\n","      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n","      (position_embeddings): Embedding(512, 768)\n","      (token_type_embeddings): Embedding(2, 768)\n","      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (dropout): Dropout(p=0.1, inplace=False)\n","    )\n","    (encoder): BertEncoder(\n","      (layer): ModuleList(\n","        (0): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (1): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (2): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (3): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (4): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (5): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (6): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (7): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (8): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (9): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (10): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","        (11): BertLayer(\n","          (attention): BertAttention(\n","            (self): BertSelfAttention(\n","              (query): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (key): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (value): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","            (output): BertSelfOutput(\n","              (dense): QuantizedLinear(\n","                in_features=768, out_features=768, bias=True\n","                (quantize_w): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_a): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (quantize_o): TorchQuantize(\n","                  (quantize): TorchBinarize()\n","                )\n","                (noise): GaussianNoise()\n","              )\n","              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","          (intermediate): BertIntermediate(\n","            (dense): QuantizedLinear(\n","              in_features=768, out_features=3072, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (intermediate_act_fn): GELUActivation()\n","          )\n","          (output): BertOutput(\n","            (dense): QuantizedLinear(\n","              in_features=3072, out_features=768, bias=True\n","              (quantize_w): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_a): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (quantize_o): TorchQuantize(\n","                (quantize): TorchBinarize()\n","              )\n","              (noise): GaussianNoise()\n","            )\n","            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (pooler): BertPooler(\n","      (dense): QuantizedLinear(\n","        in_features=768, out_features=768, bias=True\n","        (quantize_w): TorchQuantize(\n","          (quantize): TorchBinarize()\n","        )\n","        (quantize_a): TorchQuantize(\n","          (quantize): TorchBinarize()\n","        )\n","        (quantize_o): TorchQuantize(\n","          (quantize): TorchBinarize()\n","        )\n","        (noise): GaussianNoise()\n","      )\n","      (activation): Tanh()\n","    )\n","  )\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (classifier): QuantizedLinear(\n","    in_features=768, out_features=7, bias=True\n","    (quantize_w): TorchQuantize(\n","      (quantize): TorchBinarize()\n","    )\n","    (quantize_a): TorchQuantize(\n","      (quantize): TorchBinarize()\n","    )\n","    (quantize_o): TorchQuantize(\n","      (quantize): TorchBinarize()\n","    )\n","    (noise): GaussianNoise()\n","  )\n",")"]},"metadata":{},"execution_count":70}],"source":["model\n","model.cuda()"]},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"klue\", \"ynat\")\n","\n","dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":265,"referenced_widgets":["a0106c909df8414d80d725f754add732","25b2cb97a97143d58b9578225b1676ff","636b3d60bec64906b6d2f422b608689b","765daf35a8b44db8b670c64847ae2d52","dee89abcae0c46d4b1e6183cd193be57","59bceb0d70324510b4c861e9e1ac7ba2","6117193bf5ad442c9bd0d9f98d05a6b2","81bb213d2ce74d5b8d28fa202306a6b8","f00b44e51d884ea8b5360587dabadbe1","e5d710a929304e608349c51237e39230","95daa47cf87142f785b1bcf699dce9a9"]},"id":"IwiMIEveqnar","executionInfo":{"status":"ok","timestamp":1676507599142,"user_tz":-540,"elapsed":5630,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"e3d5a2cf-b99d-4b08-fd6e-c051282eed12"},"execution_count":71,"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.builder:Found cached dataset klue (/root/.cache/huggingface/datasets/klue/ynat/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e)\n"]},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0106c909df8414d80d725f754add732"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["DatasetDict({\n","    train: Dataset({\n","        features: ['guid', 'title', 'label', 'url', 'date'],\n","        num_rows: 45678\n","    })\n","    validation: Dataset({\n","        features: ['guid', 'title', 'label', 'url', 'date'],\n","        num_rows: 9107\n","    })\n","})"]},"metadata":{},"execution_count":71}]},{"cell_type":"code","source":["# load model&tokenizerx\n","tokenizer = BertTokenizerFast.from_pretrained(model_name, use_fast=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5kFUlDIGqvb_","executionInfo":{"status":"ok","timestamp":1676507599967,"user_tz":-540,"elapsed":833,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"5c9ee27e-65df-4be1-c088-b897f4104213"},"execution_count":72,"outputs":[{"output_type":"stream","name":"stderr","text":["loading file vocab.txt from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/vocab.txt\n","loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer.json\n","loading file added_tokens.json from cache at None\n","loading file special_tokens_map.json from cache at None\n","loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/tokenizer_config.json\n","loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--bert-base-multilingual-cased/snapshots/fdfce55e83dbed325647a63e7e1f5de19f0382ba/config.json\n","Model config BertConfig {\n","  \"_name_or_path\": \"bert-base-multilingual-cased\",\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"classifier_dropout\": null,\n","  \"directionality\": \"bidi\",\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"layer_norm_eps\": 1e-12,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_hidden_layers\": 12,\n","  \"pad_token_id\": 0,\n","  \"pooler_fc_size\": 768,\n","  \"pooler_num_attention_heads\": 12,\n","  \"pooler_num_fc_layers\": 3,\n","  \"pooler_size_per_head\": 128,\n","  \"pooler_type\": \"first_token_transform\",\n","  \"position_embedding_type\": \"absolute\",\n","  \"transformers_version\": \"4.26.1\",\n","  \"type_vocab_size\": 2,\n","  \"use_cache\": true,\n","  \"vocab_size\": 119547\n","}\n","\n"]}]},{"cell_type":"code","source":["def preprocess_function(examples):\n","    return tokenizer(examples['title'], max_length=max_length, truncation=True)"],"metadata":{"id":"mJL1d24Bqqgm","executionInfo":{"status":"ok","timestamp":1676507599968,"user_tz":-540,"elapsed":10,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"execution_count":73,"outputs":[]},{"cell_type":"code","execution_count":74,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"03g8ZGLhUZHX","outputId":"0c9dafe5-0adc-4b28-b817-3e575e4f59df","executionInfo":{"status":"ok","timestamp":1676507601063,"user_tz":-540,"elapsed":1104,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/ynat/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e/cache-2bc4fe5d984499c1.arrow\n","WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/klue/ynat/1.0.0/e0fc3bc3de3eb03be2c92d72fd04a60ecc71903f821619cb28ca0e1e29e4233e/cache-bbf89201527f545c.arrow\n"]},{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['guid', 'title', 'label', 'url', 'date', 'input_ids', 'token_type_ids', 'attention_mask'],\n","    num_rows: 45678\n","})"]},"metadata":{},"execution_count":74}],"source":["encoded_dataset = dataset.map(preprocess_function, batched=True)\n","encoded_dataset['train']"]},{"cell_type":"code","source":["len_dataset = len(encoded_dataset['train'])\n","len_validset = len(encoded_dataset['validation'])\n","\n","print('#train =', len_dataset,\n","      '#valid =', len_validset\n","      )\n","\n","total_batch_size = batch_size_per_device * torch.cuda.device_count()\n","n_total_iterations = int(len_dataset / total_batch_size * n_epochs)\n","n_warmup_steps = int(n_total_iterations * warmup_ratio)\n","\n","print(\n","        '#total_iters =', n_total_iterations,\n","        '#warmup_iters =', n_warmup_steps,\n","      )"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OPgfbWmurEJD","executionInfo":{"status":"ok","timestamp":1676507601064,"user_tz":-540,"elapsed":11,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"d5e18974-cfea-47b2-d00d-0180093302cb"},"execution_count":75,"outputs":[{"output_type":"stream","name":"stdout","text":["#train = 45678 #valid = 9107\n","#total_iters = 4282 #warmup_iters = 856\n"]}]},{"cell_type":"code","source":["import os\n","\n","output_dir = os.path.join(\"ynat\")\n","logging_dir = os.path.join(output_dir, 'logs')\n","args = TrainingArguments(\n","    # checkpoint\n","    output_dir=output_dir,\n","\n","    # Model Save & Load\n","    save_strategy = \"epoch\", # 'steps'\n","    load_best_model_at_end=True,\n","\n","    # Dataset\n","    num_train_epochs=n_epochs,\n","    per_device_train_batch_size= batch_size_per_device,\n","    per_device_eval_batch_size= batch_size_per_device,\n","    \n","    # Optimizer\n","    learning_rate=lr, # 5e-5\n","    weight_decay=0.01,  # 0\n","    warmup_steps=n_warmup_steps,\n","\n","    # Resularization\n","    # max_grad_norm = 1.0,\n","    # label_smoothing_factor=0.1,\n","\n","    # Use mixed precision\n","    # mixed precision mode\n","    fp16=False,                                 \n","    #fp16_opt_level=\"02\",  \n","\n","    # Evaluation \n","    metric_for_best_model='eval_f1',\n","    evaluation_strategy = \"epoch\",\n","\n","    # Logging\n","    logging_dir=logging_dir,\n","\n","    # Randomness\n","    seed=42,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KJL2AuYNrMqZ","executionInfo":{"status":"ok","timestamp":1676507601644,"user_tz":-540,"elapsed":3,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"1d30fae7-670f-4c0b-b752-aeee61f9883b"},"execution_count":76,"outputs":[{"output_type":"stream","name":"stderr","text":["PyTorch: setting up devices\n","The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"]}]},{"cell_type":"code","source":["# datasets 라이브러리에서 제공하는 Evaluation metric의 리스트를 확인합니다.\n","from datasets import list_metrics, load_metric\n","metrics_list = list_metrics()\n","len(metrics_list)\n","print(', '.join(metric for metric in metrics_list))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5PRNtbTRrUhx","executionInfo":{"status":"ok","timestamp":1676507605441,"user_tz":-540,"elapsed":1811,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"267d70de-04d5-467a-eb73-f7b7c5bbc889"},"execution_count":77,"outputs":[{"output_type":"stream","name":"stdout","text":["accuracy, bertscore, bleu, bleurt, brier_score, cer, character, charcut_mt, chrf, code_eval, comet, competition_math, coval, cuad, exact_match, f1, frugalscore, glue, google_bleu, indic_glue, mae, mahalanobis, mape, mase, matthews_correlation, mauve, mean_iou, meteor, mse, nist_mt, pearsonr, perplexity, poseval, precision, recall, rl_reliability, roc_auc, rouge, sacrebleu, sari, seqeval, smape, spearmanr, squad, squad_v2, super_glue, ter, trec_eval, wer, wiki_split, xnli, xtreme_s, BucketHeadP65/confusion_matrix, BucketHeadP65/roc_curve, Drunper/metrica_tesi, Felipehonorato/my_metric, GMFTBY/dailydialog_evaluate, GMFTBY/dailydialogevaluate, JP-SystemsX/nDCG, Josh98/nl2bash_m, KevinSpaghetti/accuracyk, NCSOFT/harim_plus, NikitaMartynov/spell-check-metric, NimaBoscarino/weat, Ochiroo/rouge_mn, Vertaix/vendiscore, Viona/infolm, Vlasta/pr_auc, abdusah/aradiawer, abidlabs/mean_iou, abidlabs/mean_iou2, angelina-wang/directional_bias_amplification, anz2/iliauniiccocrevaluation, bstrai/classification_report, cakiki/ndcg, codeparrot/apps_metric, cpllab/syntaxgym, daiyizheng/valid, dvitel/codebleu, ecody726/bertscore, erntkn/dice_coefficient, giulio98/code_eval_outputs, giulio98/codebleu, gnail/cosine_similarity, gorkaartola/metric_for_tp_fp_samples, hack/test_metric, harshhpareek/bertscore, hpi-dhc/FairEval, idsedykh/codebleu, idsedykh/codebleu2, idsedykh/megaglue, idsedykh/metric, jordyvl/ece, jpxkqx/peak_signal_to_noise_ratio, jpxkqx/signal_to_reconstrution_error, jzm-mailchimp/joshs_second_test_metric, kaggle/ai4code, kaggle/amex, kashif/mape, kasmith/woodscore, kyokote/my_metric2, leslyarun/fbeta_score, loubnabnl/apps_metric2, lvwerra/accuracy_score, lvwerra/bary_score, lvwerra/test, mfumanelli/geometric_mean, mgfrantz/roc_auc_macro, ola13/precision_at_k, omidf/squad_precision_recall, posicube/mean_reciprocal_rank, ronaldahmed/nwentfaithfulness, sportlosos/sescore, transZ/test_parascore, xu1998hz/sescore, ybelkada/cocoevaluate, yonting/average_precision_score, yulong-me/yl_metric, yzha/ctc_eval, zbeloki/m2\n"]}]},{"cell_type":"code","source":["# YNAT의 metric은 F1 score를 사용합니다.\n","metric_macrof1 = load_metric('f1')\n","\n","def compute_metrics(eval_pred):\n","    predictions = eval_pred.predictions.argmax(-1)\n","    labels = eval_pred.label_ids\n","    return metric_macrof1.compute(predictions=predictions,\n","                                  references=labels, average='macro')"],"metadata":{"id":"maLa6c2xrVUM","executionInfo":{"status":"ok","timestamp":1676507606539,"user_tz":-540,"elapsed":1104,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"execution_count":78,"outputs":[]},{"cell_type":"code","source":["from transformers import default_data_collator\n","trainer = Trainer(\n","    model,\n","    args,\n","    train_dataset=encoded_dataset[\"train\"],\n","    eval_dataset=encoded_dataset['validation'],\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics,\n",")"],"metadata":{"id":"dLiGpT3DrbWg","executionInfo":{"status":"ok","timestamp":1676507606539,"user_tz":-540,"elapsed":5,"user":{"displayName":"­황태경","userId":"13750175094392078445"}}},"execution_count":79,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":993},"id":"gL_jMPlIrds6","executionInfo":{"status":"ok","timestamp":1676508965403,"user_tz":-540,"elapsed":1357765,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"3ef3e37a-3407-45ad-d048-97210f2ee6f5"},"execution_count":80,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the training set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: url, guid, title, date. If url, guid, title, date are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running training *****\n","  Num examples = 45678\n","  Num Epochs = 3\n","  Instantaneous batch size per device = 32\n","  Total train batch size (w. parallel, distributed & accumulation) = 32\n","  Gradient Accumulation steps = 1\n","  Total optimization steps = 4284\n","  Number of trainable parameters = 177858823\n","You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='4284' max='4284' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [4284/4284 22:37, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>1.156800</td>\n","      <td>1.373251</td>\n","      <td>0.580557</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.796600</td>\n","      <td>1.220386</td>\n","      <td>0.634138</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.676700</td>\n","      <td>1.129846</td>\n","      <td>0.649780</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: url, guid, title, date. If url, guid, title, date are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9107\n","  Batch size = 32\n","Saving model checkpoint to ynat/checkpoint-1428\n","Configuration saved in ynat/checkpoint-1428/config.json\n","Model weights saved in ynat/checkpoint-1428/pytorch_model.bin\n","tokenizer config file saved in ynat/checkpoint-1428/tokenizer_config.json\n","Special tokens file saved in ynat/checkpoint-1428/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: url, guid, title, date. If url, guid, title, date are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9107\n","  Batch size = 32\n","Saving model checkpoint to ynat/checkpoint-2856\n","Configuration saved in ynat/checkpoint-2856/config.json\n","Model weights saved in ynat/checkpoint-2856/pytorch_model.bin\n","tokenizer config file saved in ynat/checkpoint-2856/tokenizer_config.json\n","Special tokens file saved in ynat/checkpoint-2856/special_tokens_map.json\n","The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: url, guid, title, date. If url, guid, title, date are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9107\n","  Batch size = 32\n","Saving model checkpoint to ynat/checkpoint-4284\n","Configuration saved in ynat/checkpoint-4284/config.json\n","Model weights saved in ynat/checkpoint-4284/pytorch_model.bin\n","tokenizer config file saved in ynat/checkpoint-4284/tokenizer_config.json\n","Special tokens file saved in ynat/checkpoint-4284/special_tokens_map.json\n","\n","\n","Training completed. Do not forget to share your model on huggingface.co/models =)\n","\n","\n","Loading best model from ynat/checkpoint-4284 (score: 0.6497803119475611).\n"]},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=4284, training_loss=0.9548048630259396, metrics={'train_runtime': 1357.8891, 'train_samples_per_second': 100.917, 'train_steps_per_second': 3.155, 'total_flos': 2010627694116300.0, 'train_loss': 0.9548048630259396, 'epoch': 3.0})"]},"metadata":{},"execution_count":80}]},{"cell_type":"code","source":["trainer.evaluate()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":236},"id":"qDTUqfMDrjUM","executionInfo":{"status":"ok","timestamp":1676503915742,"user_tz":-540,"elapsed":33810,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"76299abb-5c1b-4264-c44a-9d1dc042e3b6"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stderr","text":["The following columns in the evaluation set don't have a corresponding argument in `BertForSequenceClassification.forward` and have been ignored: url, guid, title, date. If url, guid, title, date are not expected by `BertForSequenceClassification.forward`,  you can safely ignore this message.\n","***** Running Evaluation *****\n","  Num examples = 9107\n","  Batch size = 32\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='285' max='285' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [285/285 00:34]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.7977203130722046,\n"," 'eval_f1': 0.7183172904607441,\n"," 'eval_runtime': 34.3171,\n"," 'eval_samples_per_second': 265.378,\n"," 'eval_steps_per_second': 8.305,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":29}]},{"cell_type":"code","source":["trainer.save_model('./checkpoint')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qHPuVIKsrk6y","executionInfo":{"status":"ok","timestamp":1676509107892,"user_tz":-540,"elapsed":3223,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"bf9cd3ce-290a-4b67-db2d-e4a2e46efda9"},"execution_count":81,"outputs":[{"output_type":"stream","name":"stderr","text":["Saving model checkpoint to ./checkpoint\n","Configuration saved in ./checkpoint/config.json\n","Model weights saved in ./checkpoint/pytorch_model.bin\n","tokenizer config file saved in ./checkpoint/tokenizer_config.json\n","Special tokens file saved in ./checkpoint/special_tokens_map.json\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kzygocuHN0bA"},"outputs":[],"source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","def predict(model, data_loader):\n","    print('start predict')\n","\n","    model.eval()\n","\n","    total_preds = []\n","    total_labels = []\n","\n","    for step, batch in tqdm(enumerate(data_loader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","        logit = outputs[0]\n","\n","        logit = logit.detach().cpu().numpy()\n","        label = b_labels.cpu().numpy()\n","    \n","        total_preds += np.argmax(logit, axis=1).tolist()\n","        total_labels += label.tolist()\n","\n","    f1 = f1_score(total_labels, total_preds, average='macro')\n","    avg = accuracy_score(total_labels, total_preds) * 100\n","    return f1, avg"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u_mSTZFuOBVy"},"outputs":[],"source":["test = dataset['validation']\n","test_labels = torch.tensor(test['label'])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Nu_L5PEYb-Z4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1676493297909,"user_tz":-540,"elapsed":3347,"user":{"displayName":"­황태경","userId":"13750175094392078445"}},"outputId":"e56f5ba6-badb-4a4f-aa76-d1ef5fea9bf1"},"outputs":[{"output_type":"stream","name":"stdout","text":["model:  yes  \t Size (KB): 711547.273\n","177858823\n"]}],"source":["def print_size_of_model(model, label=\"\"):\n","    torch.save(model.state_dict(), \"temp.p\")\n","    size=os.path.getsize(\"temp.p\")\n","    print(\"model: \",label,' \\t','Size (KB):', size/1e3)\n","    os.remove('temp.p')\n","    return size\n","\n","# compare the sizes\n","f=print_size_of_model(model,\"yes\")\n","print(sum(p.numel() for p in model.parameters()))"]},{"cell_type":"code","source":["def get_input_ids(data):\n","  document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in data]\n","  tokenized_texts = [tokenizer.tokenize(s) for s in tqdm(document_bert, \"Tokenizing\")]\n","  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts, \"Converting tokens to ids\")]\n","  print(\"Padding sequences...\")\n","  input_ids = pad_sequences(input_ids, maxlen=max_length, dtype='long', truncating='post', padding='post')\n","  return input_ids\n","\n","def get_attention_masks(input_ids):\n","  attention_masks = []\n","  for seq in tqdm(input_ids, \"Generating attention masks\"):\n","      seq_mask = [float(i > 0) for i in seq]\n","      attention_masks.append(seq_mask)\n","  return attention_masks"],"metadata":{"id":"VppWJd8Lr8k7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_ids = torch.tensor(get_input_ids(test['title']))\n","test_masks = torch.tensor(get_attention_masks(test_ids))\n","test_labels = torch.tensor(test['label'])"],"metadata":{"id":"nYBC-EIvsA2t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_data = TensorDataset(test_ids, test_masks, test_labels)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size_per_device)"],"metadata":{"id":"NdviNMilr_uP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import accuracy_score\n","from sklearn.metrics import f1_score\n","\n","def predict(model, data_loader):\n","    print('start predict')\n","\n","    model.eval()\n","\n","    total_preds = []\n","    total_labels = []\n","\n","    for step, batch in tqdm(enumerate(data_loader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        \n","        with torch.no_grad():\n","            outputs = model(b_input_ids,\n","                            token_type_ids=None,\n","                            attention_mask=b_input_mask)\n","        logit = outputs[0]\n","\n","        logit = logit.detach().cpu().numpy()\n","        label = b_labels.cpu().numpy()\n","    \n","        total_preds += np.argmax(logit, axis=1).tolist()\n","        total_labels += label.tolist()\n","\n","    f1 = f1_score(total_labels, total_preds, average='macro')\n","    avg = accuracy_score(total_labels, total_preds) * 100\n","    return f1, avg"],"metadata":{"id":"-dEtgdJ6r5o-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import time\n","\n","def time_model_evaluation(model, tokenizer):\n","    eval_start_time = time.time()\n","    f1, avg_test_accuracy = predict(model, test_dataloader)\n","    eval_end_time = time.time()\n","    eval_duration_time = eval_end_time - eval_start_time\n","    print(\"Accuracy : {0:.4f}\".format(avg_test_accuracy))\n","    print(\"f1 score : {0:.4f}\".format(f1))\n","    print(\"Evaluate total time (seconds) : {0:.1f}\".format(eval_duration_time))\n","\n","# Evaluate the original FP32 BERT model\n","time_model_evaluation(model, tokenizer)\n","\n","# Evaluate the INT8 BERT model after the dynamic quantization\n","time_model_evaluation(model_dynamic_quantized, tokenizer)"],"metadata":{"id":"cHS2sR1ortMn"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"mount_file_id":"1lCy-Xyo61fsIcxS4_CIqvBuefCxWl_9n","authorship_tag":"ABX9TyMPTwcH3e++9/AA7pZ2RiaC"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"a0106c909df8414d80d725f754add732":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_25b2cb97a97143d58b9578225b1676ff","IPY_MODEL_636b3d60bec64906b6d2f422b608689b","IPY_MODEL_765daf35a8b44db8b670c64847ae2d52"],"layout":"IPY_MODEL_dee89abcae0c46d4b1e6183cd193be57"}},"25b2cb97a97143d58b9578225b1676ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_59bceb0d70324510b4c861e9e1ac7ba2","placeholder":"​","style":"IPY_MODEL_6117193bf5ad442c9bd0d9f98d05a6b2","value":"100%"}},"636b3d60bec64906b6d2f422b608689b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_81bb213d2ce74d5b8d28fa202306a6b8","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f00b44e51d884ea8b5360587dabadbe1","value":2}},"765daf35a8b44db8b670c64847ae2d52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5d710a929304e608349c51237e39230","placeholder":"​","style":"IPY_MODEL_95daa47cf87142f785b1bcf699dce9a9","value":" 2/2 [00:00&lt;00:00,  8.92it/s]"}},"dee89abcae0c46d4b1e6183cd193be57":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"59bceb0d70324510b4c861e9e1ac7ba2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6117193bf5ad442c9bd0d9f98d05a6b2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"81bb213d2ce74d5b8d28fa202306a6b8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f00b44e51d884ea8b5360587dabadbe1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e5d710a929304e608349c51237e39230":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95daa47cf87142f785b1bcf699dce9a9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}